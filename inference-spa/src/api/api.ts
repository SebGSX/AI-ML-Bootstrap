/* tslint:disable */
/* eslint-disable */
/**
 * AI/ML Bootstrap
 * A bootstrap guide and project to get a curious developer up and running on artificial intelligence andmachine learning.
 *
 * The version of the OpenAPI document: v1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


import type { Configuration } from './configuration';
import type { AxiosPromise, AxiosInstance, AxiosRequestConfig } from 'axios';
import globalAxios from 'axios';
// Some imports not used depending on template conditions
// @ts-ignore
import { DUMMY_BASE_URL, assertParamExists, setApiKeyToObject, setBasicAuthToObject, setBearerAuthToObject, setOAuthToObject, setSearchParams, serializeDataIfNeeded, toPathString, createRequestFunction } from './common';
import type { RequestArgs } from './base';
// @ts-ignore
import { BASE_PATH, COLLECTION_FORMATS, BaseAPI, RequiredError } from './base';

/**
 * Represents a request for the inference engine.
 * @export
 * @interface Request
 */
export interface Request {
    /**
     * A string representing the request\'s text.
     * @type {string}
     * @memberof Request
     */
    'text'?: string | null;
}
/**
 * Represents a response from the inference engine.
 * @export
 * @interface Response
 */
export interface Response {
    /**
     * A string representing the response\'s text.
     * @type {string}
     * @memberof Response
     */
    'text'?: string | null;
}

/**
 * InferenceApi - axios parameter creator
 * @export
 */
export const InferenceApiAxiosParamCreator = function (configuration?: Configuration) {
    return {
        /**
         * 
         * @summary Gets a response from the inference engine by submitting a textual request.
         * @param {Request} [request] A InferenceEngine.Request representing a textual request.
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        inferencePost: async (request?: Request, options: AxiosRequestConfig = {}): Promise<RequestArgs> => {
            const localVarPath = `/Inference`;
            // use dummy base URL string because the URL constructor only accepts absolute URLs.
            const localVarUrlObj = new URL(localVarPath, DUMMY_BASE_URL);
            let baseOptions;
            if (configuration) {
                baseOptions = configuration.baseOptions;
            }

            const localVarRequestOptions = { method: 'POST', ...baseOptions, ...options};
            const localVarHeaderParameter = {} as any;
            const localVarQueryParameter = {} as any;


    
            localVarHeaderParameter['Content-Type'] = 'application/json';

            setSearchParams(localVarUrlObj, localVarQueryParameter);
            let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
            localVarRequestOptions.headers = {...localVarHeaderParameter, ...headersFromBaseOptions, ...options.headers};
            localVarRequestOptions.data = serializeDataIfNeeded(request, localVarRequestOptions, configuration)

            return {
                url: toPathString(localVarUrlObj),
                options: localVarRequestOptions,
            };
        },
    }
};

/**
 * InferenceApi - functional programming interface
 * @export
 */
export const InferenceApiFp = function(configuration?: Configuration) {
    const localVarAxiosParamCreator = InferenceApiAxiosParamCreator(configuration)
    return {
        /**
         * 
         * @summary Gets a response from the inference engine by submitting a textual request.
         * @param {Request} [request] A InferenceEngine.Request representing a textual request.
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        async inferencePost(request?: Request, options?: AxiosRequestConfig): Promise<(axios?: AxiosInstance, basePath?: string) => AxiosPromise<Response>> {
            const localVarAxiosArgs = await localVarAxiosParamCreator.inferencePost(request, options);
            return createRequestFunction(localVarAxiosArgs, globalAxios, BASE_PATH, configuration);
        },
    }
};

/**
 * InferenceApi - factory interface
 * @export
 */
export const InferenceApiFactory = function (configuration?: Configuration, basePath?: string, axios?: AxiosInstance) {
    const localVarFp = InferenceApiFp(configuration)
    return {
        /**
         * 
         * @summary Gets a response from the inference engine by submitting a textual request.
         * @param {Request} [request] A InferenceEngine.Request representing a textual request.
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        inferencePost(request?: Request, options?: any): AxiosPromise<Response> {
            return localVarFp.inferencePost(request, options).then((request) => request(axios, basePath));
        },
    };
};

/**
 * InferenceApi - object-oriented interface
 * @export
 * @class InferenceApi
 * @extends {BaseAPI}
 */
export class InferenceApi extends BaseAPI {
    /**
     * 
     * @summary Gets a response from the inference engine by submitting a textual request.
     * @param {Request} [request] A InferenceEngine.Request representing a textual request.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof InferenceApi
     */
    public inferencePost(request?: Request, options?: AxiosRequestConfig) {
        return InferenceApiFp(this.configuration).inferencePost(request, options).then((request) => request(this.axios, this.basePath));
    }
}


